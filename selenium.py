# -*- coding: utf-8 -*-
"""selenium.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bOrHCzToy8MPXDRd8IBfAiV-jelbjuDl
"""

import pandas as pd
import numpy as np
from google.colab import drive
drive.mount('drive')

!pip install selenium
!apt-get update # to update ubuntu to correctly run apt install
!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin

import sys
sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')
from selenium import webdriver
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')
wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

wd.get('https://www.flipkart.com/search?q=laptop')
#print('Flipkart' in 'wd.title')
#print(wd.title)
wd.find_element_by_xpath("//*[@id='container']/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[1]")
posts = wd.find_elements_by_class_name('_4rR01T')
for post in posts:
  print(post.text)

# Laptop Info data scrapping from flipkart website using selenium
#product_class =  WebDriverWait(wd, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, '._1fQZEK')))
product_class = wd.find_elements_by_class_name('_1fQZEK')
print(product_class)
product_info = []
for product in product_class:
  name = product.find_element_by_xpath('//*[@id="container"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[1]/div[1]')
  if name:
    name = name.text 
  else:
    name = "No name"
  #print(name)
  price = product.find_element_by_xpath('//*[@id="container"]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a/div[2]/div[2]/div[1]/div[1]/div[1]')
  if price:
    price = price.text
  #print(price)
  rating = product.find_element_by_xpath('//*[@id="productRating_LSTCOMGFVWMDZPGK4WRWRM8ES_COMGFVWMDZPGK4WR_"]/div')
  if rating:
    rating = rating.text
  #print(rating)  
  product_info.append((name,price,rating))

#print(product_info)
df = pd.DataFrame(product_info)
df.columns = ['Laptop_Name', 'Price','Rating']
df = df.drop([df.index[0],df.index[1]])
print(df.head())
df.to_csv('Laptop_info.csv')
!cp Laptop_info.csv "drive/My Drive/"



# Laptop Info data scrapping from flipkart website using selenium
#product_class =  WebDriverWait(wd, 20).until(EC.presence_of_element_located((By.CSS_SELECTOR, '._1fQZEK')))
driver.get('https://www.naukri.com/business-analyst-jobs?k=business%20analyst')
#job_class = driver.find_elements_by_class_name('title fw500 ellipsis')
job_class = driver.find_elements_by_xpath('//*[@id="root"]/div[3]/div[2]/section[2]/div[2]/article[1]/div[1]/div[1]/a')
print(job_class)
#print(post_class)
job_info = []
for job in job_class:
  job_name = job.find_element_by_xpath('//*[@id="root"]/div[3]/div[2]/section[2]/div[2]/article[1]/div[1]/div[1]/a')
  if job_name:
    job_name = job_name.text 
  else:
    job_name = "No name"
  #print(name)
  company = job.find_element_by_xpath('//*[@id="root"]/div[3]/div[2]/section[2]/div[2]/article[1]/div[1]/div[1]/div/a[1]')
  if company:
    company = company.text
  #print(price)
  rating = job.find_element_by_xpath('//*[@id="root"]/div[3]/div[2]/section[2]/div[2]/article[1]/div[1]/div[1]/div/span')
  if rating:
    rating = rating.text
  #print(rating)  
  product_info.append((job_name,company,rating))

print(job_info)
df = pd.DataFrame(job_info)
df.columns = ['Job_Name', 'Company','Rating']
#df = df.drop([df.index[0],df.index[1]])
print(df.head())
df.to_csv('job_info.csv')
!cp job_info.csv "drive/My Drive/"